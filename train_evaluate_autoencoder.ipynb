{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from AutoEncoder import AutoEncoder \n",
    "import argparse\n",
    "import numpy as np     \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device selected:  cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if cuda is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Set proper device based on cuda availability \n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Torch device selected: \", device)\n",
    "\n",
    "# Create transformations to apply to each data sample \n",
    "# Can specify variations such as image flip, color flip, random crop, ...\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "# Load datasets for training and testing\n",
    "# Inbuilt datasets available in torchvision (check documentation online)\n",
    "dataset1 = datasets.MNIST('./data/', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('./data/', train=False,\n",
    "                    transform=transform)\n",
    "\n",
    "def load_data(batch_size=10, num_workers=2):\n",
    "    '''\n",
    "    This function loads dataloaders based on the given batchsize\n",
    "    '''\n",
    "    train_loader = DataLoader(dataset1, batch_size = batch_size, \n",
    "                            shuffle=True, num_workers=num_workers)\n",
    "    test_loader = DataLoader(dataset2, batch_size = batch_size, \n",
    "                                shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot(num_epochs, train_losses, train_accuracies, best_accuracy, save=0, mode=1):\n",
    "    ''' this function is to plot the train accuracies and train losses over iterations\n",
    "    Args:\n",
    "        num_epochs (int): total number of iterations (x-axis)\n",
    "        train_losses (list): a list of all the losses after each iteration\n",
    "        train_accuracies (list): a list of all the accuracies after each iteration\n",
    "        best_accuracy (float): the best accuracy of the model\n",
    "        save (int): if save == 1, the plot will be saved as a jpg image\n",
    "        mode (int): the model number \n",
    "    '''\n",
    "    x = range(1, num_epochs+1)\n",
    "\n",
    "    # displaying the title\n",
    "    plt.title(f'plots/model_{mode}.jpg')\n",
    "    plt.plot(x, train_losses)\n",
    "    plt.plot(x, train_accuracies)\n",
    "    plt.legend(['Train Loss', 'Train Accuracy'], title=f'Accuracy = {best_accuracy: .2f}')\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'plots/model_{mode}.jpg')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def train(mode, model, device, train_loader, optimizer, criterion, epoch, batch_size, num_epochs):\n",
    "    '''\n",
    "    Trains the model for an epoch and optimizes it.\n",
    "    model: The model to train. Should already be in correct device.\n",
    "    device: 'cuda' or 'cpu'.\n",
    "    train_loader: dataloader for training samples.\n",
    "    optimizer: optimizer to use for model parameter updates.\n",
    "    criterion: used to compute loss for prediction and target \n",
    "    epoch: Current epoch to train for.\n",
    "    batch_size: Batch size to be used.\n",
    "    '''\n",
    "    \n",
    "    # Set model to train mode before each epoch\n",
    "    model.train()\n",
    "    \n",
    "    # Empty list to store losses \n",
    "    losses = []\n",
    "    correct = 0\n",
    "    # Iterate over entire training samples (1 epoch)\n",
    "    for batch_idx, batch_sample in enumerate(train_loader):\n",
    "        data, target = batch_sample\n",
    "        # print(f'{data.shape = }')\n",
    "\n",
    "        if mode == 1: # FC layers\n",
    "            data = data.reshape(-1, 28*28)\n",
    "        # Push data/label to correct device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset optimizer gradients. Avoids grad accumulation (accumulation used in RNN).\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Do forward pass for current set of data\n",
    "        output = model(data)\n",
    "\n",
    "        # Compute loss based on criterion\n",
    "        loss = criterion(output, data)\n",
    "        # Computes gradient based on final loss\n",
    "        loss.backward()\n",
    "        # Store loss\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Optimize model parameters based on learning rate and gradient \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Get predicted index by selecting maximum log-probability\n",
    "        # pred = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        # _, predictions = output.max(1)\n",
    "        # correct += (predictions == target).sum()\n",
    "        print('Training epoch: ({}/{}) batch: ({}/{})'.format(epoch, num_epochs, batch_idx+1, len(train_loader)), end='\\r') #. Acc: {correct}/{(batch_idx+1) * batch_size}, {100. * correct / ((batch_idx+1) * batch_size)}', end='\\r')\n",
    "        \n",
    "    train_loss = float(np.mean(losses))\n",
    "    train_acc = correct / ((batch_idx+1) * batch_size)\n",
    "    print('\\nTrain set ({}/{}): Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(epoch, num_epochs,\n",
    "        float(np.mean(losses)), correct, (batch_idx+1) * batch_size,\n",
    "        100. * correct / ((batch_idx+1) * batch_size)))\n",
    "    return train_loss, train_acc\n",
    "    \n",
    "def test(mode, model, device, test_loader, criterion, epoch, num_epochs, batch_size):\n",
    "    '''\n",
    "    Tests the model.\n",
    "    model: The model to train. Should already be in correct device.\n",
    "    device: 'cuda' or 'cpu'.\n",
    "    test_loader: dataloader for test samples.\n",
    "    '''\n",
    "    \n",
    "    # Set model to eval mode to notify all layers.\n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct = 0\n",
    "    \n",
    "    # Set torch.no_grad() to disable gradient computation and backpropagation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, sample in enumerate(test_loader):\n",
    "            data, target = sample\n",
    "            if mode == 1:\n",
    "                data = data.reshape(-1, 28*28)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Predict for data by doing forward pass\n",
    "            output = model(data)\n",
    "        \n",
    "            # Compute loss based on same criterion as training \n",
    "            loss = criterion(output, data)\n",
    "            \n",
    "            # Append loss to overall test loss\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Get predicted index by selecting maximum log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "            _, predictions = output.max(1)\n",
    "            # correct += (predictions == target).sum()\n",
    "            print('Testing epoch: ({}/{}) batch: ({}/{})'.format(epoch, num_epochs, batch_idx+1, len(test_loader)), end='\\r')\n",
    "\n",
    "    test_loss = float(np.mean(losses))\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set ({}/{}): Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(epoch, num_epochs,\n",
    "        test_loss, correct, len(test_loader.dataset), accuracy))\n",
    "    \n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================ Training model 1 ================================\n",
      "\n",
      "learning_rate = 0.1\n",
      "batch_size = 10\n",
      "num_epochs = 10\n",
      "\n",
      "Training epoch: (1/10) batch: (6000/6000)\n",
      "Train set (1/10): Average loss: 0.7451, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (1/10) batch: (1000/1000)\n",
      "Test set (1/10): Average loss: 0.6500, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (2/10) batch: (6000/6000)\n",
      "Train set (2/10): Average loss: 0.6279, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (2/10) batch: (1000/1000)\n",
      "Test set (2/10): Average loss: 0.6153, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (3/10) batch: (6000/6000)\n",
      "Train set (3/10): Average loss: 0.6032, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (3/10) batch: (1000/1000)\n",
      "Test set (3/10): Average loss: 0.5959, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (4/10) batch: (6000/6000)\n",
      "Train set (4/10): Average loss: 0.5842, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (4/10) batch: (1000/1000)\n",
      "Test set (4/10): Average loss: 0.5785, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (5/10) batch: (6000/6000)\n",
      "Train set (5/10): Average loss: 0.5687, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (5/10) batch: (1000/1000)\n",
      "Test set (5/10): Average loss: 0.5661, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (6/10) batch: (6000/6000)\n",
      "Train set (6/10): Average loss: 0.5583, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (6/10) batch: (1000/1000)\n",
      "Test set (6/10): Average loss: 0.5572, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (7/10) batch: (6000/6000)\n",
      "Train set (7/10): Average loss: 0.5500, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (7/10) batch: (1000/1000)\n",
      "Test set (7/10): Average loss: 0.5495, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (8/10) batch: (6000/6000)\n",
      "Train set (8/10): Average loss: 0.5425, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (8/10) batch: (1000/1000)\n",
      "Test set (8/10): Average loss: 0.5433, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (9/10) batch: (6000/6000)\n",
      "Train set (9/10): Average loss: 0.5369, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (9/10) batch: (1000/1000)\n",
      "Test set (9/10): Average loss: 0.5384, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (10/10) batch: (6000/6000)\n",
      "Train set (10/10): Average loss: 0.5320, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (10/10) batch: (1000/1000)\n",
      "Test set (10/10): Average loss: 0.5342, Accuracy: 0/10000 (0%)\n",
      "\n",
      "accuracy is 0.00\n",
      "Training and evaluation finished\n",
      "================================================================================\n",
      "================================ Training model 2 ================================\n",
      "\n",
      "learning_rate = 0.1\n",
      "batch_size = 10\n",
      "num_epochs = 10\n",
      "\n",
      "Training epoch: (1/10) batch: (6000/6000)\n",
      "Train set (1/10): Average loss: 0.4909, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (1/10) batch: (1000/1000)\n",
      "Test set (1/10): Average loss: 0.4829, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (2/10) batch: (6000/6000)\n",
      "Train set (2/10): Average loss: 0.4753, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (2/10) batch: (1000/1000)\n",
      "Test set (2/10): Average loss: 0.4803, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (3/10) batch: (6000/6000)\n",
      "Train set (3/10): Average loss: 0.4735, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (3/10) batch: (1000/1000)\n",
      "Test set (3/10): Average loss: 0.4791, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (4/10) batch: (6000/6000)\n",
      "Train set (4/10): Average loss: 0.4725, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (4/10) batch: (1000/1000)\n",
      "Test set (4/10): Average loss: 0.4783, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (5/10) batch: (6000/6000)\n",
      "Train set (5/10): Average loss: 0.4719, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (5/10) batch: (1000/1000)\n",
      "Test set (5/10): Average loss: 0.4778, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (6/10) batch: (6000/6000)\n",
      "Train set (6/10): Average loss: 0.4714, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (6/10) batch: (1000/1000)\n",
      "Test set (6/10): Average loss: 0.4774, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (7/10) batch: (6000/6000)\n",
      "Train set (7/10): Average loss: 0.4710, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (7/10) batch: (1000/1000)\n",
      "Test set (7/10): Average loss: 0.4772, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (8/10) batch: (6000/6000)\n",
      "Train set (8/10): Average loss: 0.4707, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (8/10) batch: (1000/1000)\n",
      "Test set (8/10): Average loss: 0.4769, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (9/10) batch: (6000/6000)\n",
      "Train set (9/10): Average loss: 0.4705, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (9/10) batch: (1000/1000)\n",
      "Test set (9/10): Average loss: 0.4766, Accuracy: 0/10000 (0%)\n",
      "\n",
      "Training epoch: (10/10) batch: (6000/6000)\n",
      "Train set (10/10): Average loss: 0.4703, Accuracy: 0/60000 (0%)\n",
      "\n",
      "Testing epoch: (10/10) batch: (1000/1000)\n",
      "Test set (10/10): Average loss: 0.4764, Accuracy: 0/10000 (0%)\n",
      "\n",
      "accuracy is 0.00\n",
      "Training and evaluation finished\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_model(mode=1, learning_rate=0.01, batch_size=10, num_epochs=60):\n",
    "    '''\n",
    "    this function computes training and testing with the given hyper-parameters \n",
    "    Args:\n",
    "        mode (int): which model to run\n",
    "        learning_rate (float): the learning rate for the optimizer\n",
    "        batch_size (int): how many images does the model see for each batch\n",
    "        num_epochs (int): how many times the model sees the entire dataset\n",
    "    '''\n",
    "    print('\\nlearning_rate = {}\\nbatch_size = {}\\nnum_epochs = {}\\n'.format(learning_rate, batch_size, num_epochs))\n",
    "    # the input of the model\n",
    "    image_size = 28*28\n",
    "    # the output of the model\n",
    "    num_classes = 10\n",
    "\n",
    "    # Initialize the model and send to device \n",
    "    model = AutoEncoder(mode, image_size, num_classes).to(device)\n",
    "    # Define loss function.\n",
    "    criterion = nn.MSELoss()\n",
    "    # Define optimizer function.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    # Define data loaders\n",
    "    train_loader, test_loader = load_data(batch_size)\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    # Run training for n_epochs specified in config \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # compute the accuracy and lost for each epoch\n",
    "        train_loss, train_accuracy = train(mode, model, device, train_loader, optimizer, criterion, epoch, batch_size, num_epochs)\n",
    "        test_loss, test_accuracy = test(mode, model, device, test_loader, criterion, epoch, num_epochs, batch_size)\n",
    "        \n",
    "        # store the best test accuracy\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "\n",
    "        # save the train accuracy and train loss for this epoch so that we can plot it later\n",
    "        train_losses.append(train_loss)\n",
    "        # train_accuracies.append(train_accuracy.cpu().numpy())\n",
    "\n",
    "    # after the training is completed plot the losses and accuracies against the epochs\n",
    "    # plot(num_epochs, train_losses, train_accuracies, best_accuracy, save=1, mode=mode)\n",
    "\n",
    "    print(\"accuracy is {:2.2f}\".format(best_accuracy))\n",
    "\n",
    "    print(\"Training and evaluation finished\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ================== Model 1 ==================\n",
    "learning_rate = 0.1\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "print('\\n\\n'+('='*32)+' Training model 1 '+('='*32))\n",
    "model1 = run_model(mode=1, learning_rate=learning_rate, batch_size=batch_size, num_epochs=num_epochs)    \n",
    "print('='*80)\n",
    "\n",
    "# ================== Model 2 ==================\n",
    "learning_rate = 0.1\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "print(('='*32)+' Training model 2 '+('='*32))\n",
    "\n",
    "model2 = run_model(mode=2, learning_rate=learning_rate, batch_size=batch_size, num_epochs=num_epochs)\n",
    "print('='*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def show(org, recon_img):\n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    axarr[0].imshow(org, cmap='gray')\n",
    "    axarr[1].imshow(recon_img, cmap='gray')\n",
    "    # plt.imshow(img, cmap='gray')\n",
    "    \n",
    "\n",
    "def show_recon_images(mode, model, device, test_loader):\n",
    "    '''\n",
    "    Tests the model.\n",
    "    model: The model to train. Should already be in correct device.\n",
    "    device: 'cuda' or 'cpu'.\n",
    "    test_loader: dataloader for test samples.\n",
    "    '''\n",
    "    data = {}\n",
    "    # Set model to eval mode to notify all layers.\n",
    "    model.eval()\n",
    "    # Set torch.no_grad() to disable gradient computation and backpropagation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, sample in enumerate(test_loader):\n",
    "            img, target = sample\n",
    "\n",
    "            target = target.numpy()[0]\n",
    "            if target not in data.keys():\n",
    "                data[target] = [img]\n",
    "            else:\n",
    "                data[target].append(img)\n",
    "\n",
    "    for target, images in data.items():\n",
    "        for i, image in enumerate(images[:2]):\n",
    "            if mode == 1:\n",
    "                image = image.reshape(-1, 28*28)\n",
    "            image = image.to(device)\n",
    "            # Predict for data by doing forward pass\n",
    "            output = model(image)\n",
    "            output = output.reshape(-1, 28, 28).detach().numpy()[0]\n",
    "            image = image.reshape(-1, 28, 28)[0]\n",
    "            # show(image, output)\n",
    "            # f, axarr = plt.subplots(1,2)\n",
    "            # axarr[0].imshow(image, cmap='gray')\n",
    "            # axarr[1].imshow(output, cmap='gray')\n",
    "\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.title(\"Original\")\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(output, cmap='gray')\n",
    "            plt.title(\"Re-constructed\")\n",
    "\n",
    "            plt.suptitle(target)\n",
    "\n",
    "            save_path = f'outputs/model{mode}/{target}/'\n",
    "            if not os.path.exists(save_path):\n",
    "                os.mkdir(save_path)\n",
    "            \n",
    "            plt.savefig(save_path+f'{target}_{i}.jpg')\n",
    "        # break\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define loss function.\n",
    "criterion = nn.MSELoss()\n",
    "# Define optimizer function.\n",
    "# Define data loaders\n",
    "train_loader, test_loader = load_data(batch_size=1)\n",
    "\n",
    "mode = 1\n",
    "show_recon_images(mode, model1, device, test_loader)\n",
    "\n",
    "mode = 2\n",
    "show_recon_images(mode, model2, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
